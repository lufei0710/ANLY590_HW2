{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "n9lOwkQjHfkY",
        "colab_type": "code",
        "outputId": "51c4554e-da6d-4c1d-fdb3-b4931cf7d9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import gzip\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "from tensorflow.python import keras\n",
        "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model,Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vmj-4lBU-yEN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Getting data\n",
        "\n",
        "train = pd.read_csv('fashion-mnist_train.csv')\n",
        "test = pd.read_csv('fashion-mnist_test.csv')\n",
        "\n",
        "print\n",
        "# get data and labels\n",
        "train_data= np.array(train.iloc[:,1:])\n",
        "test_data= np.array(test.iloc[:,1:])\n",
        "train_labels= np.array(train.iloc[:,0]) \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ui9QI9onQUt3",
        "colab_type": "code",
        "outputId": "5c57c339-53a5-409e-a6b6-8879b927c830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# preprocess the data\n",
        "train_data = train_data.reshape(-1, 28,28, 1)\n",
        "test_data = test_data.reshape(-1, 28,28, 1)\n",
        "print(train_data.dtype)\n",
        "print(train_data.shape)\n",
        "\n",
        "train_data = train_data / np.max(train_data)\n",
        "test_data = test_data / np.max(test_data)\n",
        "print(np.max(train_data))\n",
        "\n",
        "# split train and validation\n",
        "train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,\n",
        "                                                             train_data,\n",
        "                                                             test_size=0.2,\n",
        "                                                             random_state=13)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int64\n",
            "(60000, 28, 28, 1)\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yMWY7cDIS5nB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the encode part of the CNN\n",
        "def encoder(input_img):\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) \n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) \n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) \n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) \n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) \n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) \n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    return conv4\n",
        "\n",
        "# The decode part of the cnn\n",
        "def decoder(conv4):    \n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5) \n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
        "    up1 = UpSampling2D((2,2))(conv6) \n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) \n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
        "    up2 = UpSampling2D((2,2))(conv7) \n",
        "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) \n",
        "    return decoded\n",
        " \n",
        "\n",
        "input_img = Input(shape = (28, 28, 1))\n",
        "\n",
        "# combine and compile the model\n",
        "autoencoder = Model(input_img, decoder(encoder(input_img)))\n",
        "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zNvBKbOYv6Ld",
        "colab_type": "code",
        "outputId": "7d5b8d6d-f9c3-48a0-a0d2-f8c0739e114f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "\n",
        "autoencoder.fit(train_X, train_ground, batch_size=64,epochs=10,verbose=1,validation_data=(valid_X, valid_ground))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 59s 1ms/step - loss: 0.0195 - val_loss: 0.0127\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0092 - val_loss: 0.0075\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0067 - val_loss: 0.0058\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0057 - val_loss: 0.0109\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0051 - val_loss: 0.0048\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0047 - val_loss: 0.0041\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0037 - val_loss: 0.0046\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0035 - val_loss: 0.0036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6900cd5470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "6-_3fDzwzNu4",
        "colab_type": "code",
        "outputId": "ac88586c-254e-4a11-fa1d-d318daaf0595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "cell_type": "code",
      "source": [
        "# plot the original pictures and reconstructed pictures\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n=5\n",
        "for k in range(n):\n",
        "    ax = plt.subplot(2, n, k+1)\n",
        "    plt.imshow(test_data[k:k+1,:].reshape((28,28)))\n",
        "    ax = plt.subplot(2, n, k+1 + n)\n",
        "    reconstruction = autoencoder.predict(test_data[k:k+1,:])\n",
        "    reconstruction.resize((28,28))\n",
        "    plt.imshow(reconstruction)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAESCAYAAAC8dt8yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f68f7c5ab38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UgTPpS-hpOjN",
        "colab_type": "code",
        "outputId": "b92b8b8a-e6f8-46be-b860-574138f8db75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "cell_type": "code",
      "source": [
        "# Question 2\n",
        "\n",
        "\n",
        "#Model\n",
        "# For this cnn\n",
        "# I used two convolunational layers both with 2x2 kernel size since the dimension of the image is not that large\n",
        "# each convolutional layer is followed by a max pooling layer that reduces the size by 2\n",
        "# I chose same padding so that the input is padded to a multiple of 2\n",
        "# the activation function I chose is relu for both convlutional layers\n",
        "\n",
        "# that I flatten the input\n",
        "# followed by a regular fully connected hidden layer with 256 neurons and a activation function of relu\n",
        "# then a dropout layer to possibly reduce overfitting\n",
        "# then finally a final fully connected output layer with softmax probabilities functions\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(2,2), padding = 'same', activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=32, kernel_size=(2, 2), padding='same', \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(output_dim = 10, activation = 'softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 28, 28, 64)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 14, 14, 32)        8224      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 412,778\n",
            "Trainable params: 412,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rtOZnZwmJWI0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split training and validations\n",
        "# get dummies for labels\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data,\n",
        "                                                  train_labels,\n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=13)\n",
        "\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_val = pd.get_dummies(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "okaY5FyfDUyr",
        "colab_type": "code",
        "outputId": "b2d0e773-b2bf-4346-b6c3-5910ffc34be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0824 - acc: 0.9688 - val_loss: 0.2737 - val_acc: 0.9218\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0731 - acc: 0.9728 - val_loss: 0.2742 - val_acc: 0.9219\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0653 - acc: 0.9757 - val_loss: 0.2987 - val_acc: 0.9170\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0616 - acc: 0.9767 - val_loss: 0.3094 - val_acc: 0.9184\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0589 - acc: 0.9784 - val_loss: 0.3090 - val_acc: 0.9218\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0523 - acc: 0.9805 - val_loss: 0.3278 - val_acc: 0.9210\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0520 - acc: 0.9806 - val_loss: 0.3186 - val_acc: 0.9210\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0471 - acc: 0.9830 - val_loss: 0.3346 - val_acc: 0.9207\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0440 - acc: 0.9831 - val_loss: 0.3384 - val_acc: 0.9207\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0411 - acc: 0.9849 - val_loss: 0.3595 - val_acc: 0.9218\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0389 - acc: 0.9861 - val_loss: 0.3626 - val_acc: 0.9218\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0359 - acc: 0.9868 - val_loss: 0.3701 - val_acc: 0.9191\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0386 - acc: 0.9858 - val_loss: 0.3632 - val_acc: 0.9197\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0313 - acc: 0.9887 - val_loss: 0.3904 - val_acc: 0.9204\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0330 - acc: 0.9888 - val_loss: 0.3907 - val_acc: 0.9210\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 5s 115us/step - loss: 0.0311 - acc: 0.9883 - val_loss: 0.3790 - val_acc: 0.9226\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0304 - acc: 0.9889 - val_loss: 0.3850 - val_acc: 0.9214\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0291 - acc: 0.9889 - val_loss: 0.4052 - val_acc: 0.9222\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0280 - acc: 0.9899 - val_loss: 0.4276 - val_acc: 0.9204\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 5s 114us/step - loss: 0.0264 - acc: 0.9902 - val_loss: 0.4194 - val_acc: 0.9204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89f1c31278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "N49jQWOCSwwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Question 2.2\n",
        "from keras.applications import VGG16;\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "78LWLPFIXQ8p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('fashion-mnist_train.csv')\n",
        "test_data = pd.read_csv('fashion-mnist_test.csv')\n",
        "\n",
        "# get data and labels\n",
        "train_X= np.array(train_data.iloc[:,1:])\n",
        "test_X= np.array(test_data.iloc[:,1:])\n",
        "train_Y= np.array (train_data.iloc[:,0]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZZOlde67HENY",
        "colab_type": "code",
        "outputId": "aa747438-e807-4ab3-eff7-4996e41f5c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_X=np.dstack([train_X] * 3)\n",
        "test_X=np.dstack([test_X]*3)\n",
        "\n",
        "train_X = train_X.reshape(-1, 28,28,3)\n",
        "test_X= test_X.reshape (-1,28,28,3)\n",
        "\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "\n",
        "train_X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in train_X])\n",
        "test_X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in test_X])\n",
        "\n",
        "train_X.shape, test_X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 48, 48, 3), (10000, 48, 48, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "ls6O2jjNIVMT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_X = train_X / 255.\n",
        "test_X = test_X / 255.\n",
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z77_wPqxIfNE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3AQc3aRMIgOK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_X,valid_X,train_label,valid_label = train_test_split(train_X,\n",
        "                                                           train_Y_one_hot,\n",
        "                                                           test_size=0.2,\n",
        "                                                           random_state=13\n",
        "                                                           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "77h2OVDEIkDl",
        "colab_type": "code",
        "outputId": "384426e1-26f3-49bc-d3b5-477b5e6017f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 48, 48, 3), (12000, 48, 48, 3), (48000, 10), (12000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "yitKakXOIo-B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "IMG_WIDTH = 48\n",
        "IMG_HEIGHT = 48\n",
        "IMG_DEPTH = 3\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_X = preprocess_input(train_X)\n",
        "valid_X = preprocess_input(valid_X)\n",
        "test_X  = preprocess_input (test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ikWvLF1WIvZf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# base model \n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False, \n",
        "                  input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH)\n",
        "                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hurNyGYXJCN9",
        "colab_type": "code",
        "outputId": "d93399eb-9dce-4c60-808d-f8eceab82c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Extracting features\n",
        "train_features = conv_base.predict(np.array(train_X), batch_size=BATCH_SIZE, verbose=1)\n",
        "test_features = conv_base.predict(np.array(test_X), batch_size=BATCH_SIZE, verbose=1)\n",
        "val_features = conv_base.predict(np.array(valid_X), batch_size=BATCH_SIZE, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 52s 1ms/step\n",
            "10000/10000 [==============================] - 10s 1ms/step\n",
            "12000/12000 [==============================] - 13s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "99IdiXjRJZJL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Flatten extracted features\n",
        "train_features_flat = np.reshape(train_features, (48000, 1*1*512))\n",
        "test_features_flat = np.reshape(test_features, (10000, 1*1*512))\n",
        "val_features_flat = np.reshape(val_features, (12000, 1*1*512))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mwcXyL57JH_S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "NB_TRAIN_SAMPLES = train_features_flat.shape[0]\n",
        "NB_VALIDATION_SAMPLES = val_features_flat.shape[0]\n",
        "NB_EPOCHS = 100\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_dim=(1*1*512)))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizers.Adam(),\n",
        "    metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pBP7JZ2pKK00",
        "colab_type": "code",
        "outputId": "9775b790-4c71-4b5d-c510-81591fa9d48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_features_flat,\n",
        "    train_label,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features_flat, valid_label)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 8s 177us/step - loss: 0.8215 - acc: 0.6982 - val_loss: 0.8181 - val_acc: 0.7002\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 9s 181us/step - loss: 0.8142 - acc: 0.7013 - val_loss: 0.8521 - val_acc: 0.6744\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 9s 181us/step - loss: 0.8101 - acc: 0.7024 - val_loss: 0.7953 - val_acc: 0.7095\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 9s 182us/step - loss: 0.7986 - acc: 0.7070 - val_loss: 0.7795 - val_acc: 0.7192\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 9s 181us/step - loss: 0.7939 - acc: 0.7083 - val_loss: 0.7815 - val_acc: 0.7140\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 9s 181us/step - loss: 0.7918 - acc: 0.7091 - val_loss: 0.8021 - val_acc: 0.7047\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 9s 181us/step - loss: 0.7832 - acc: 0.7115 - val_loss: 0.7962 - val_acc: 0.6974\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 9s 181us/step - loss: 0.7816 - acc: 0.7116 - val_loss: 0.8343 - val_acc: 0.6890\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 9s 182us/step - loss: 0.7828 - acc: 0.7117 - val_loss: 0.7887 - val_acc: 0.7147\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 9s 181us/step - loss: 0.7685 - acc: 0.7192 - val_loss: 0.8415 - val_acc: 0.6832\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 9s 180us/step - loss: 0.7688 - acc: 0.7185 - val_loss: 0.8067 - val_acc: 0.7107\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 9s 181us/step - loss: 0.7645 - acc: 0.7192 - val_loss: 0.7756 - val_acc: 0.7188\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 9s 180us/step - loss: 0.7593 - acc: 0.7214 - val_loss: 0.7604 - val_acc: 0.7254\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 9s 180us/step - loss: 0.7594 - acc: 0.7223 - val_loss: 0.7555 - val_acc: 0.7193\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 9s 181us/step - loss: 0.7578 - acc: 0.7239 - val_loss: 0.8200 - val_acc: 0.7056\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 9s 179us/step - loss: 0.7501 - acc: 0.7261 - val_loss: 0.7325 - val_acc: 0.7284\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 9s 178us/step - loss: 0.7508 - acc: 0.7260 - val_loss: 0.8222 - val_acc: 0.6950\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 9s 181us/step - loss: 0.7474 - acc: 0.7244 - val_loss: 0.7408 - val_acc: 0.7312\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 9s 180us/step - loss: 0.7474 - acc: 0.7257 - val_loss: 0.7316 - val_acc: 0.7314\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 9s 179us/step - loss: 0.7405 - acc: 0.7270 - val_loss: 0.7422 - val_acc: 0.7278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffa09f6af98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "sLDbVb0pzDVN",
        "colab_type": "code",
        "outputId": "56a7a462-446e-4b13-c836-ab1347cc0d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Question 3.1\n",
        "\n",
        "# getting the data\n",
        "beg = pd.read_csv('benign-urls.txt')\n",
        "mal = pd.read_csv('malicious-urls.txt', header = None)\n",
        "mal['label'] = 1\n",
        "beg['label'] = 0\n",
        "\n",
        "mal.columns = ['text', 'label']\n",
        "beg.columns = ['text', 'label']\n",
        "\n",
        "\n",
        "url_data = pd.concat([mal, beg])\n",
        "\n",
        "\n",
        "# proprocess the data\n",
        "class_zero = url_data[url_data['label'] == 0].reset_index()\n",
        "class_one = url_data[url_data['label'] == 1].reset_index()\n",
        "\n",
        "class_zero = class_zero.truncate(before=1, after=class_one.shape[0])\n",
        "\n",
        "url_data = pd.concat([class_zero, class_one])\n",
        "url_data = url_data.sample(frac=1.0).reset_index()\n",
        "\n",
        "\n",
        "# getting a character level model for the data\n",
        "char2idx = dict()\n",
        "max_url_seq_length = 0\n",
        "for url in url_data['text']:\n",
        "    max_url_seq_length = max(max_url_seq_length, len(url))\n",
        "    for c in url:\n",
        "      if c not in char2idx:\n",
        "        char2idx[c] = len(char2idx)\n",
        "num_input_tokens = len(char2idx)\n",
        "idx2char = dict([(idx, c) for c, idx in char2idx.items()])\n",
        "\n",
        "config = dict()\n",
        "config['num_input_tokens'] = num_input_tokens\n",
        "config['char2idx'] = char2idx\n",
        "config['idx2char'] = idx2char\n",
        "config['max_url_seq_length'] = max_url_seq_length\n",
        "\n",
        "print(config)\n",
        "\n",
        "text_model = config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'num_input_tokens': 39, 'char2idx': {'.': 0, 'g': 1, 'o': 2, 'l': 3, 'e': 4, 'c': 5, 'm': 6, 'f': 7, 'a': 8, 'n': 9, 'u': 10, 's': 11, 'b': 12, 'y': 13, 'd': 14, 'i': 15, 't': 16, 'r': 17, 'h': 18, 'p': 19, 'v': 20, 'j': 21, '2': 22, '5': 23, 'w': 24, 'x': 25, 'k': 26, 'z': 27, '3': 28, '7': 29, '4': 30, '-': 31, '8': 32, '1': 33, 'q': 34, '0': 35, '6': 36, 'G': 37, '9': 38}, 'idx2char': {0: '.', 1: 'g', 2: 'o', 3: 'l', 4: 'e', 5: 'c', 6: 'm', 7: 'f', 8: 'a', 9: 'n', 10: 'u', 11: 's', 12: 'b', 13: 'y', 14: 'd', 15: 'i', 16: 't', 17: 'r', 18: 'h', 19: 'p', 20: 'v', 21: 'j', 22: '2', 23: '5', 24: 'w', 25: 'x', 26: 'k', 27: 'z', 28: '3', 29: '7', 30: '4', 31: '-', 32: '8', 33: '1', 34: 'q', 35: '0', 36: '6', 37: 'G', 38: '9'}, 'max_url_seq_length': 58}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DjuC9m0KFdPC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function for extracting url data\n",
        "def extract_training_data(url_data):\n",
        "        data_size = url_data.shape[0]\n",
        "        X = np.zeros(shape=(data_size, max_url_seq_length, num_input_tokens))\n",
        "        Y = np.zeros(shape=(data_size, 2))\n",
        "        for i in range(data_size):\n",
        "            url = url_data['text'][i]\n",
        "            label = url_data['label'][i]\n",
        "            for idx, c in enumerate(url):\n",
        "                X[i, idx, char2idx[c]] = 1\n",
        "            Y[i, label] = 1\n",
        "\n",
        "        return X, Y\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8G3CXVYi6TTy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build a LSTM model\n",
        "from keras.layers import LSTM, Dense, Dropout, Activation\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "NB_LSTM_CELLS = 256\n",
        "NB_DENSE_CELLS = 256\n",
        "\n",
        "num_input_tokens = text_model['num_input_tokens']\n",
        "char2idx = text_model['char2idx']\n",
        "idx2char = text_model['idx2char']\n",
        "max_url_seq_length = text_model['max_url_seq_length']\n",
        "\n",
        "X, Y = extract_training_data(url_data)\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=13)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(NB_LSTM_CELLS, input_shape=(None, num_input_tokens), return_sequences=False, return_state=False, dropout=0.2))\n",
        "model.add(Dense(NB_DENSE_CELLS))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "msfAgRfGGalh",
        "colab_type": "code",
        "outputId": "dce4e1be-7480-4742-ed52-ab0ea5facca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(Xtrain, Ytrain, batch_size=batch_size, epochs=epochs, verbose=1,\n",
        "                                 validation_data=(Xtest, Ytest))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2073 samples, validate on 519 samples\n",
            "Epoch 1/10\n",
            "2073/2073 [==============================] - 7s 3ms/step - loss: 0.6952 - acc: 0.5070 - val_loss: 0.6927 - val_acc: 0.5125\n",
            "Epoch 2/10\n",
            "2073/2073 [==============================] - 5s 2ms/step - loss: 0.6933 - acc: 0.4945 - val_loss: 0.6940 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "2073/2073 [==============================] - 5s 2ms/step - loss: 0.6931 - acc: 0.5200 - val_loss: 0.6925 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "2073/2073 [==============================] - 5s 2ms/step - loss: 0.6921 - acc: 0.5162 - val_loss: 0.6852 - val_acc: 0.5703\n",
            "Epoch 5/10\n",
            "2073/2073 [==============================] - 5s 2ms/step - loss: 0.4911 - acc: 0.7926 - val_loss: 0.2914 - val_acc: 0.8979\n",
            "Epoch 6/10\n",
            "2073/2073 [==============================] - 5s 2ms/step - loss: 0.3771 - acc: 0.8490 - val_loss: 0.3197 - val_acc: 0.9345\n",
            "Epoch 7/10\n",
            "2073/2073 [==============================] - 5s 2ms/step - loss: 0.3139 - acc: 0.8751 - val_loss: 0.3370 - val_acc: 0.9345\n",
            "Epoch 8/10\n",
            "2073/2073 [==============================] - 5s 2ms/step - loss: 0.3356 - acc: 0.8818 - val_loss: 0.2528 - val_acc: 0.9152\n",
            "Epoch 9/10\n",
            "2073/2073 [==============================] - 5s 2ms/step - loss: 0.3047 - acc: 0.8857 - val_loss: 0.3028 - val_acc: 0.9306\n",
            "Epoch 10/10\n",
            "2073/2073 [==============================] - 5s 2ms/step - loss: 0.3067 - acc: 0.8799 - val_loss: 0.2692 - val_acc: 0.9268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89d9729828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "metadata": {
        "id": "91-3P43XX7g5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Question 3.2\n",
        "from keras.layers import Embedding, SpatialDropout1D, Conv1D, MaxPooling1D, LSTM, Dense\n",
        "\n",
        "\n",
        "NB_LSTM_CELLS = 256\n",
        "NB_DENSE_CELLS = 256\n",
        "EMBEDDING_SIZE = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oWIZJP71drzN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function for extracting data from url dataframe\n",
        "def extract_training_data(url_data):\n",
        "        data_size = url_data.shape[0]\n",
        "        X = np.zeros(shape=(data_size, max_url_seq_length))\n",
        "        Y = np.zeros(shape=(data_size, 2))\n",
        "        for i in range(data_size):\n",
        "            url = url_data['text'][i]\n",
        "            label = url_data['label'][i]\n",
        "            for idx, c in enumerate(url):\n",
        "                X[i, idx] = char2idx[c]\n",
        "            Y[i, label] = 1\n",
        "\n",
        "        return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bzf2V5aqdyV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get data\n",
        "X, Y = extract_training_data(url_data)\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=1994)\n",
        "\n",
        "# Build model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_input_tokens, input_length=max_url_seq_length, output_dim=EMBEDDING_SIZE))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Conv1D(filters=256, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(Dense(units=2, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_7ianhsEfDgm",
        "colab_type": "code",
        "outputId": "7a3611f7-72eb-4d6f-9574-1763e4ede432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(Xtrain, Ytrain, batch_size=64, epochs=10, verbose=1,\n",
        "                                 validation_data=(Xtest, Ytest))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2073 samples, validate on 519 samples\n",
            "Epoch 1/10\n",
            "2073/2073 [==============================] - 4s 2ms/step - loss: 0.5061 - acc: 0.6922 - val_loss: 0.2552 - val_acc: 0.9017\n",
            "Epoch 2/10\n",
            "2073/2073 [==============================] - 2s 939us/step - loss: 0.1561 - acc: 0.9489 - val_loss: 0.0860 - val_acc: 0.9672\n",
            "Epoch 3/10\n",
            "2073/2073 [==============================] - 2s 938us/step - loss: 0.1178 - acc: 0.9614 - val_loss: 0.1065 - val_acc: 0.9788\n",
            "Epoch 4/10\n",
            "2073/2073 [==============================] - 2s 967us/step - loss: 0.0797 - acc: 0.9802 - val_loss: 0.0713 - val_acc: 0.9807\n",
            "Epoch 5/10\n",
            "2073/2073 [==============================] - 2s 973us/step - loss: 0.0485 - acc: 0.9870 - val_loss: 0.1290 - val_acc: 0.9557\n",
            "Epoch 6/10\n",
            "2073/2073 [==============================] - 2s 976us/step - loss: 0.0938 - acc: 0.9686 - val_loss: 0.0781 - val_acc: 0.9769\n",
            "Epoch 7/10\n",
            "2073/2073 [==============================] - 2s 969us/step - loss: 0.0461 - acc: 0.9879 - val_loss: 0.0592 - val_acc: 0.9807\n",
            "Epoch 8/10\n",
            "2073/2073 [==============================] - 2s 972us/step - loss: 0.0437 - acc: 0.9865 - val_loss: 0.0731 - val_acc: 0.9769\n",
            "Epoch 9/10\n",
            "2073/2073 [==============================] - 2s 968us/step - loss: 0.0249 - acc: 0.9928 - val_loss: 0.0589 - val_acc: 0.9788\n",
            "Epoch 10/10\n",
            "2073/2073 [==============================] - 2s 969us/step - loss: 0.0174 - acc: 0.9932 - val_loss: 0.0729 - val_acc: 0.9769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89d8414a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "metadata": {
        "id": "IVGyVmFXiK0z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Questions 3.3\n",
        "\n",
        "# from the validation accuracy on the data\n",
        "# it seems like cnn produces a better result"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}